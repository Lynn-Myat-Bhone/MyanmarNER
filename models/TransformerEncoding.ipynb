{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "N-_RXQTAqWhl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-_RXQTAqWhl",
        "outputId": "e7623544-802a-44cb-bb92-21d10f36ac23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ebc74ea7",
      "metadata": {
        "id": "ebc74ea7",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1DUeTjUbqMXk",
      "metadata": {
        "id": "1DUeTjUbqMXk"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, filepath, word2idx, pos2idx, tag2idx):\n",
        "        self.word2idx = word2idx\n",
        "        self.pos2idx = pos2idx\n",
        "        self.tag2idx = tag2idx\n",
        "        self.sentences, self.pos_tags, self.ner_tags = self.load_data(filepath)\n",
        "\n",
        "    def load_data(self, filepath):\n",
        "        sentences, pos_tags, ner_tags = [], [], []\n",
        "        sentence, pos_seq, ner_seq = [], [], []\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    parts = line.split(\"\\t\")\n",
        "                    if len(parts) >= 3:\n",
        "                        word, pos, ner = parts\n",
        "                        sentence.append(word)\n",
        "                        pos_seq.append(pos)\n",
        "                        ner_seq.append(ner)\n",
        "                else:\n",
        "                    if sentence:\n",
        "                        sentences.append(sentence)\n",
        "                        pos_tags.append(pos_seq)\n",
        "                        ner_tags.append(ner_seq)\n",
        "                        sentence, pos_seq, ner_seq = [], [], []\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "                pos_tags.append(pos_seq)\n",
        "                ner_tags.append(ner_seq)\n",
        "        return sentences, pos_tags, ner_tags\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word_ids = [self.word2idx.get(w, self.word2idx[\"<UNK>\"]) for w in self.sentences[idx]]\n",
        "        pos_ids = [self.pos2idx.get(p, self.pos2idx[\"<UNK>\"]) for p in self.pos_tags[idx]]\n",
        "        tag_ids = [self.tag2idx.get(t, self.tag2idx[\"<UNK>\"]) for t in self.ner_tags[idx]]\n",
        "        return {\n",
        "                \"input_ids\": word_ids,\n",
        "                \"pos_ids\": pos_ids,\n",
        "                \"ner_ids\": tag_ids}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [sample[\"input_ids\"] for sample in batch]\n",
        "    pos_ids = [sample[\"pos_ids\"] for sample in batch]\n",
        "    ner_ids = [sample[\"ner_ids\"] for sample in batch]\n",
        "\n",
        "    max_len = max(len(seq) for seq in input_ids)\n",
        "    pad = 0\n",
        "\n",
        "    padded_input_ids = [seq + [pad] * (max_len - len(seq)) for seq in input_ids]\n",
        "    padded_pos_ids   = [seq + [pad] * (max_len - len(seq)) for seq in pos_ids]\n",
        "    padded_ner_ids   = [seq + [pad] * (max_len - len(seq)) for seq in ner_ids]\n",
        "    attention_masks  = [[1 if i < len(seq) else 0 for i in range(max_len)] for seq in input_ids]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(padded_input_ids, dtype=torch.long),\n",
        "        torch.tensor(padded_pos_ids, dtype=torch.long),\n",
        "        torch.tensor(padded_ner_ids, dtype=torch.long),\n",
        "        torch.tensor(attention_masks, dtype=torch.bool),\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "uhkHXmoz4Lhp",
      "metadata": {
        "id": "uhkHXmoz4Lhp"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/Datasets/train_v5.conll\"\n",
        "val_path = \"/content/drive/MyDrive/Datasets/val_v5.conll\"\n",
        "test_path = \"/content/drive/MyDrive/Datasets/test_v5.conll\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VP9MDl5CshWD",
      "metadata": {
        "id": "VP9MDl5CshWD"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "uw8kNsdQJfi0",
      "metadata": {
        "id": "uw8kNsdQJfi0"
      },
      "outputs": [],
      "source": [
        "#Force reinstall compatible versions\n",
        "# !pip install gensim\n",
        "# !pip install numpy==1.24.3 --force-reinstall\n",
        "# !pip install pytorch-crf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dQexvLD-JDmp",
      "metadata": {
        "id": "dQexvLD-JDmp"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Datasets/cc.my.300.vec', binary=False)\n",
        "# https://fasttext.cc/docs/en/crawl-vectors.html choose Burmese choose text .vec file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "LVhMJrOhqTbL",
      "metadata": {
        "id": "LVhMJrOhqTbL"
      },
      "outputs": [],
      "source": [
        "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "ner_tag_to_ix = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "pos_tag_to_ix = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "\n",
        "train_data = CustomDataset(train_path, vocab, pos_tag_to_ix, ner_tag_to_ix)\n",
        "val_data = CustomDataset(val_path, vocab, pos_tag_to_ix, ner_tag_to_ix)\n",
        "test_data = CustomDataset(test_path, vocab, pos_tag_to_ix, ner_tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bKgC1EDo7_yV",
      "metadata": {
        "id": "bKgC1EDo7_yV"
      },
      "outputs": [],
      "source": [
        "# Build vocab and tag mappings from datasets\n",
        "for dataset in [train_data, val_data, test_data]:\n",
        "    for sentence, pos_tags, ner_tags in zip(dataset.sentences, dataset.pos_tags, dataset.ner_tags):\n",
        "        for word in sentence:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = len(vocab)\n",
        "        for ner_tag in ner_tags:\n",
        "            if ner_tag not in ner_tag_to_ix:\n",
        "                ner_tag_to_ix[ner_tag] = len(ner_tag_to_ix)\n",
        "        for pos_tag in pos_tags:\n",
        "            if pos_tag not in pos_tag_to_ix:\n",
        "                pos_tag_to_ix[pos_tag] = len(pos_tag_to_ix)\n",
        "\n",
        "# Load FastText embeddings\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(vocab), embedding_dim))  # init with zeros\n",
        "\n",
        "for word, idx in vocab.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[idx] = fasttext_model[word]\n",
        "    elif word == \"\":\n",
        "        embedding_matrix[idx] = np.zeros(embedding_dim)\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
        "\n",
        "# Convert to torch tensor\n",
        "fasttext_embeddings = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "\n",
        "# Reverse lookup for decoding\n",
        "ix_to_ner_tag = {v: k for k, v in ner_tag_to_ix.items()}\n",
        "ix_to_pos_tag = {v: k for k, v in pos_tag_to_ix.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "UygE2C1H8I_B",
      "metadata": {
        "id": "UygE2C1H8I_B"
      },
      "outputs": [],
      "source": [
        "for dataset in [train_data, val_data, test_data]:\n",
        "    dataset.word2idx = vocab\n",
        "    dataset.tag2idx = ner_tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5_vP5Jbn8LLb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_vP5Jbn8LLb",
        "outputId": "772c50c4-4f3c-4a10-c9a8-8ce17eaa0507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19304\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 256\n",
        "vocab_size = len(vocab)\n",
        "num_ner_tags = len(ner_tag_to_ix)\n",
        "print(vocab_size)\n",
        "print(num_ner_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Ds9qpDWi8OpR",
      "metadata": {
        "id": "Ds9qpDWi8OpR"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_f2UlPQHP4Hp",
      "metadata": {
        "id": "_f2UlPQHP4Hp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from TorchCRF import CRF \n",
        "\n",
        "class TransformerNER(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_ner_tags, num_pos_tags, dropout=0.3, num_layers=2):\n",
        "        super(TransformerNER, self).__init__()\n",
        "        dim = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.position_embedding = nn.Embedding(512, dim)  # max_len = 512\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            d_model=dim,\n",
        "            nhead=6,\n",
        "            dim_feedforward=1024,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.ner_classifier = nn.Linear(dim, num_ner_tags)\n",
        "        self.pos_classifier = nn.Linear(dim, num_pos_tags)\n",
        "        self.crf_ner = CRF(num_ner_tags, batch_first=True)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.embedding(x)\n",
        "        x = self.embedding_dropout(x)\n",
        "\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0).expand(x.size(0), -1)\n",
        "        x = x + self.position_embedding(positions)\n",
        "\n",
        "        # PyTorch expects padding mask as True for pad\n",
        "        x = self.encoder(x, src_key_padding_mask=~mask)\n",
        "\n",
        "        ner_logits = self.ner_classifier(x)\n",
        "        pos_logits = self.pos_classifier(x)\n",
        "        return ner_logits, pos_logits\n",
        "\n",
        "    def loss(self, ner_emissions, ner_tags, pos_logits, pos_tags, mask, alpha=1.0, ner_weights=None, pos_weights=None):\n",
        "        # NER loss (weighted token-level CrossEntropy if weights provided, otherwise CRF)\n",
        "        ner_logits_flat = ner_emissions.view(-1, ner_emissions.size(-1))\n",
        "        ner_targets_flat = ner_tags.view(-1)\n",
        "\n",
        "        if ner_weights is not None:\n",
        "            token_loss = F.cross_entropy(ner_logits_flat, ner_targets_flat, weight=ner_weights, ignore_index=0)\n",
        "        else:\n",
        "            token_loss = -self.crf_ner(ner_emissions, ner_tags, mask=mask, reduction='mean')\n",
        "\n",
        "        # POS loss (always CrossEntropy)\n",
        "        pos_logits_flat = pos_logits.view(-1, pos_logits.size(-1))\n",
        "        pos_targets_flat = pos_tags.view(-1)\n",
        "\n",
        "        ce_loss = F.cross_entropy(pos_logits_flat, pos_targets_flat, weight=pos_weights, ignore_index=0)\n",
        "\n",
        "        return token_loss + alpha * ce_loss, token_loss.item(), ce_loss.item()\n",
        "\n",
        "    def decode(self, ner_emissions, mask):\n",
        "        return self.crf_ner.decode(ner_emissions, mask=mask)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "Nbpa5kOXSs3q",
      "metadata": {
        "id": "Nbpa5kOXSs3q"
      },
      "outputs": [],
      "source": [
        "model = TransformerNER(\n",
        "    embedding_matrix=fasttext_embeddings,\n",
        "    num_ner_tags=len(ner_tag_to_ix),\n",
        "    num_pos_tags=len(pos_tag_to_ix)\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ZacBXeYsUyo7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZacBXeYsUyo7",
        "outputId": "f30db142-d9cb-47e2-adc9-ebb9431d6ac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  Train Loss: 7.4835 | NER: 5.9346, POS: 1.5489\n",
            "  Val   Loss: 4.4137 | NER: 3.2585, POS: 1.1552\n",
            "Epoch 2/15\n",
            "  Train Loss: 4.1091 | NER: 3.0800, POS: 1.0291\n",
            "  Val   Loss: 3.1656 | NER: 2.4054, POS: 0.7602\n",
            "Epoch 3/15\n",
            "  Train Loss: 3.0745 | NER: 2.3299, POS: 0.7446\n",
            "  Val   Loss: 2.6280 | NER: 2.0581, POS: 0.5700\n",
            "Epoch 4/15\n",
            "  Train Loss: 2.5071 | NER: 1.9126, POS: 0.5945\n",
            "  Val   Loss: 2.4234 | NER: 1.9128, POS: 0.5105\n",
            "Epoch 5/15\n",
            "  Train Loss: 2.1389 | NER: 1.6343, POS: 0.5046\n",
            "  Val   Loss: 2.1296 | NER: 1.7108, POS: 0.4188\n",
            "Epoch 6/15\n",
            "  Train Loss: 1.8638 | NER: 1.4217, POS: 0.4421\n",
            "  Val   Loss: 1.9795 | NER: 1.6170, POS: 0.3625\n",
            "Epoch 7/15\n",
            "  Train Loss: 1.6410 | NER: 1.2496, POS: 0.3914\n",
            "  Val   Loss: 1.7871 | NER: 1.4720, POS: 0.3151\n",
            "Epoch 8/15\n",
            "  Train Loss: 1.4545 | NER: 1.1042, POS: 0.3503\n",
            "  Val   Loss: 1.8215 | NER: 1.5194, POS: 0.3022\n",
            "Epoch 9/15\n",
            "  Train Loss: 1.3295 | NER: 1.0098, POS: 0.3196\n",
            "  Val   Loss: 1.6818 | NER: 1.4226, POS: 0.2592\n",
            "Epoch 10/15\n",
            "  Train Loss: 1.1727 | NER: 0.8798, POS: 0.2928\n",
            "  Val   Loss: 1.6893 | NER: 1.4489, POS: 0.2404\n",
            "Epoch 11/15\n",
            "  Train Loss: 1.0804 | NER: 0.8078, POS: 0.2726\n",
            "  Val   Loss: 1.6743 | NER: 1.4425, POS: 0.2318\n",
            "Epoch 12/15\n",
            "  Train Loss: 0.9788 | NER: 0.7271, POS: 0.2516\n",
            "  Val   Loss: 1.6233 | NER: 1.4006, POS: 0.2227\n",
            "Epoch 13/15\n",
            "  Train Loss: 0.8942 | NER: 0.6565, POS: 0.2377\n",
            "  Val   Loss: 1.6067 | NER: 1.3980, POS: 0.2088\n",
            "Epoch 14/15\n",
            "  Train Loss: 0.8311 | NER: 0.6067, POS: 0.2244\n",
            "  Val   Loss: 1.6747 | NER: 1.4789, POS: 0.1958\n",
            "Epoch 15/15\n",
            "  Train Loss: 0.7779 | NER: 0.5654, POS: 0.2126\n",
            "  Val   Loss: 1.6238 | NER: 1.4391, POS: 0.1847\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 15\n",
        "alpha = 1.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, total_ner_loss, total_pos_loss = 0.0, 0.0, 0.0\n",
        "\n",
        "    for input_ids, pos_ids, ner_ids, attention_mask in train_loader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        pos_ids = pos_ids.to(device)\n",
        "        ner_ids = ner_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ner_logits, pos_logits = model(input_ids, mask=attention_mask)\n",
        "        loss, ner_loss_val, pos_loss_val = model.loss(\n",
        "            ner_logits,\n",
        "            ner_ids,\n",
        "            pos_logits,\n",
        "            pos_ids,\n",
        "            mask=attention_mask,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_ner_loss += ner_loss_val\n",
        "        total_pos_loss += pos_loss_val\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_ner_loss, val_pos_loss = 0.0, 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for input_ids, pos_ids, ner_ids, attention_mask in val_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            pos_ids = pos_ids.to(device)\n",
        "            ner_ids = ner_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            ner_logits, pos_logits = model(input_ids, mask=attention_mask)\n",
        "            loss, ner_loss_val, pos_loss_val = model.loss(\n",
        "                ner_logits,\n",
        "                ner_ids,\n",
        "                pos_logits,\n",
        "                pos_ids,\n",
        "                mask=attention_mask,\n",
        "                alpha=alpha\n",
        "            )\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_ner_loss += ner_loss_val\n",
        "            val_pos_loss += pos_loss_val\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f} | NER: {total_ner_loss / len(train_loader):.4f}, POS: {total_pos_loss / len(train_loader):.4f}\")\n",
        "    print(f\"  Val   Loss: {avg_val_loss:.4f} | NER: {val_ner_loss / len(val_loader):.4f}, POS: {val_pos_loss / len(val_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2iCktKo3WXx6",
      "metadata": {
        "id": "2iCktKo3WXx6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "\n",
        "def evaluate_ner(model, test_loader, ner_tag_to_ix, device=device):\n",
        "    model.eval()\n",
        "    ix_to_ner = {v: k for k, v in ner_tag_to_ix.items()}\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentences, pos_tags, ner_tags, attention_mask in test_loader:\n",
        "            sentences = sentences.to(device)\n",
        "            ner_tags = ner_tags.to(device)\n",
        "            attention_mask = attention_mask.to(device).bool()\n",
        "\n",
        "            ner_emissions, _ = model(sentences, mask=attention_mask)\n",
        "            predictions = model.decode(ner_emissions, mask=attention_mask)\n",
        "\n",
        "            for i in range(len(predictions)):\n",
        "                true_len = attention_mask[i].sum().item()\n",
        "                pred_seq = predictions[i][:true_len]\n",
        "                true_seq = ner_tags[i][:true_len].cpu().tolist()\n",
        "\n",
        "                all_preds.extend([ix_to_ner[p] for p in pred_seq])\n",
        "                all_labels.extend([ix_to_ner[t] for t in true_seq])\n",
        "\n",
        "    print(\"\\nüßæ NER Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4, zero_division=0))\n",
        "\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "zekIuzU_BSry",
      "metadata": {
        "id": "zekIuzU_BSry"
      },
      "outputs": [],
      "source": [
        "# Save only the model's parameters\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"vocab\": vocab,\n",
        "    \"pos_tag_to_ix\": pos_tag_to_ix,\n",
        "    \"ner_tag_to_ix\": ner_tag_to_ix,\n",
        "}, \"TransformerEncoding_model_ver1.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94v72yZ1FiOf",
      "metadata": {
        "id": "94v72yZ1FiOf"
      },
      "source": [
        "#### Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "WmnyxdnUFkGT",
      "metadata": {
        "id": "WmnyxdnUFkGT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "\n",
        "def evaluate_model(model, dataloader, ner_tag_to_ix, device):\n",
        "    model.eval()\n",
        "    ix_to_ner_tag = {v: k for k, v in ner_tag_to_ix.items()}\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, pos_ids, ner_ids, attention_mask in dataloader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            ner_ids = ner_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            ner_logits, _ = model(input_ids, mask=attention_mask)\n",
        "            predictions = model.decode(ner_logits, mask=attention_mask)\n",
        "\n",
        "            # Flatten predictions and labels\n",
        "            for i in range(len(input_ids)):\n",
        "                length = attention_mask[i].sum().item()\n",
        "                true_seq = ner_ids[i][:length].tolist()\n",
        "                pred_seq = predictions[i][:length]\n",
        "\n",
        "                all_targets.extend([ix_to_ner_tag[ix] for ix in true_seq])\n",
        "                all_preds.extend([ix_to_ner_tag[ix] for ix in pred_seq])\n",
        "\n",
        "    print(\"NER Evaluation Report:\")\n",
        "    print(classification_report(all_targets, all_preds, digits=4, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "xM9YcFhkWvjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM9YcFhkWvjJ",
        "outputId": "e564d89a-4fb2-4383-ecdf-b07953c43a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER Evaluation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-DATE     0.8548    0.8030    0.8281        66\n",
            "       B-LOC     0.9760    0.9645    0.9702      1182\n",
            "       B-NUM     0.2500    0.2667    0.2581        15\n",
            "       B-ORG     0.7097    0.4583    0.5570        48\n",
            "       B-PER     0.6522    0.8824    0.7500        34\n",
            "      B-TIME     0.4667    0.7778    0.5833         9\n",
            "      E-DATE     0.8281    0.8030    0.8154        66\n",
            "       E-LOC     0.9795    0.9679    0.9736      1182\n",
            "       E-NUM     0.2500    0.2667    0.2581        15\n",
            "       E-ORG     0.5641    0.4583    0.5057        48\n",
            "       E-PER     0.6750    0.7941    0.7297        34\n",
            "      E-TIME     0.5714    0.8889    0.6957         9\n",
            "      I-DATE     0.7727    0.8947    0.8293        38\n",
            "       I-LOC     0.9839    0.9702    0.9770       503\n",
            "       I-ORG     0.4667    0.3590    0.4058        39\n",
            "      I-TIME     0.0000    0.0000    0.0000         0\n",
            "           O     0.9873    0.9886    0.9879     21324\n",
            "      S-DATE     0.9487    0.8409    0.8916        88\n",
            "       S-LOC     0.5528    0.7177    0.6246       124\n",
            "       S-NUM     0.9302    0.9263    0.9283       475\n",
            "       S-ORG     0.7500    0.4286    0.5455        21\n",
            "       S-PER     0.6792    0.6457    0.6621       223\n",
            "      S-TIME     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    accuracy                         0.9743     25543\n",
            "   macro avg     0.6456    0.6567    0.6425     25543\n",
            "weighted avg     0.9749    0.9743    0.9744     25543\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model, test_loader, ner_tag_to_ix, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "QKpHLo0LX23B",
      "metadata": {
        "id": "QKpHLo0LX23B"
      },
      "outputs": [],
      "source": [
        "def predict_single_sentence(model, sentence, word2idx, ner_idx2tag, device, max_len=128):\n",
        "    model.eval()\n",
        "\n",
        "    # Token to index\n",
        "    input_ids = [word2idx.get(word, word2idx[\"<UNK>\"]) for word in sentence]\n",
        "    length = len(input_ids)\n",
        "\n",
        "    # Pad\n",
        "    input_ids += [word2idx[\"<PAD>\"]] * (max_len - length)\n",
        "    attention_mask = [1]*length + [0]*(max_len - length)\n",
        "\n",
        "    # To tensor\n",
        "    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "    mask_tensor = torch.tensor([attention_mask], dtype=torch.bool).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        ner_logits, _ = model(input_tensor, mask=mask_tensor)\n",
        "        predictions = model.decode(ner_logits, mask=mask_tensor)[0][:length]  # only first row, no padding\n",
        "\n",
        "    # Convert to tag names\n",
        "    tag_names = [ner_idx2tag[tag_id] for tag_id in predictions]\n",
        "\n",
        "    return list(zip(sentence, tag_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "gTMPzL8bXMFv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTMPzL8bXMFv",
        "outputId": "d9107d7f-a55b-4c5c-e3f1-cb4ac7c93ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "·ÅÅ·Åâ·ÅÑ·Åà            ‚Üí B-DATE\n",
            "·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫          ‚Üí I-DATE\n",
            "·Äá·Äî·Ä∫·Äî·Äù·Ä´·Äõ·ÄÆ        ‚Üí I-DATE\n",
            "·Äú               ‚Üí I-DATE\n",
            "·ÅÑ               ‚Üí I-DATE\n",
            "·Äõ·ÄÄ·Ä∫·Äî·Ä±·Ä∑·Äê·ÄΩ·ÄÑ·Ä∫      ‚Üí O\n",
            "·Äô·Äº·Äî·Ä∫·Äô·Ä¨          ‚Üí B-LOC\n",
            "·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂         ‚Üí E-LOC\n",
            "·Äú·ÄΩ·Äê·Ä∫·Äú·Äï·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏    ‚Üí O\n",
            "·Äõ·Äõ·Äæ·Ä≠·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã     ‚Üí O\n"
          ]
        }
      ],
      "source": [
        "# Example sentence\n",
        "sentence = [\"·ÅÅ·Åâ·ÅÑ·Åà\", \"·ÄÅ·ÄØ·Äî·Äæ·ÄÖ·Ä∫\", \"·Äá·Äî·Ä∫·Äî·Äù·Ä´·Äõ·ÄÆ\", \"·Äú\", \"·ÅÑ\", \"·Äõ·ÄÄ·Ä∫·Äî·Ä±·Ä∑·Äê·ÄΩ·ÄÑ·Ä∫\", \"·Äô·Äº·Äî·Ä∫·Äô·Ä¨\", \"·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÑ·Ä∂\", \"·Äú·ÄΩ·Äê·Ä∫·Äú·Äï·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\", \"·Äõ·Äõ·Äæ·Ä≠·ÄÅ·Ä≤·Ä∑·Äû·Ää·Ä∫·Åã\"]\n",
        "\n",
        "# Run prediction\n",
        "results = predict_single_sentence(model, sentence, vocab, ix_to_ner_tag, device)\n",
        "\n",
        "# Print\n",
        "for word, tag in results:\n",
        "    print(f\"{word:15} ‚Üí {tag}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WtsFBuwgcU9r",
      "metadata": {
        "id": "WtsFBuwgcU9r"
      },
      "source": [
        "END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
