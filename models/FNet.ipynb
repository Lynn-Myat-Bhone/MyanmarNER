{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "N-_RXQTAqWhl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-_RXQTAqWhl",
        "outputId": "d18b8086-92ad-40e0-b2c0-ed7ce97b36b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ebc74ea7",
      "metadata": {
        "id": "ebc74ea7",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1DUeTjUbqMXk",
      "metadata": {
        "id": "1DUeTjUbqMXk"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,filepath):\n",
        "        self.sentences , self.ner_tags = self.load_data(filepath)\n",
        "\n",
        "    def load_data(self,filepath):\n",
        "        sentences, ner_tags = [],[]\n",
        "        sentence, ner_tag = [],[]\n",
        "        with open(filepath,\"r\",encoding = \"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    word,_,ner = line.split(\"\\t\")\n",
        "                    sentence.append(word)\n",
        "                    ner_tag.append(ner)\n",
        "                else:\n",
        "                    if sentence:\n",
        "                        sentences.append(sentence)\n",
        "                        ner_tags.append(ner_tag)\n",
        "            return sentences,ner_tags\n",
        "    def __len__(self):\n",
        "      return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.sentences[idx], self.ner_tags[idx]\n",
        "\n",
        "def collate_fn(self,batch):\n",
        "  sentences,tag = zip(*batch)\n",
        "  max_len = max(len(s) for s in sentences)\n",
        "  padded_sentences = [  s+ [0] * (max_len-len(s)) for s in sentences]\n",
        "  padded_tag = [ t + [0] *(max_len-len(t)) for t in tag]\n",
        "\n",
        "  return torch.tensor(padded_sentences),torch.tensor(padded_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VP9MDl5CshWD",
      "metadata": {
        "id": "VP9MDl5CshWD"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "LVhMJrOhqTbL",
      "metadata": {
        "id": "LVhMJrOhqTbL"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/Datasets/train_v5.conll\"\n",
        "val_path = \"/content/drive/MyDrive/Datasets/val_v5.conll\"\n",
        "test_path = \"/content/drive/MyDrive/Datasets/test_v5.conll\"\n",
        "\n",
        "train_data = CustomDataset(train_path)\n",
        "val_data = CustomDataset(val_path)\n",
        "test_data = CustomDataset(test_path)\n",
        "\n",
        "train_load = DataLoader(train_data, batch_size=32, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2254898",
      "metadata": {},
      "source": [
        "### Pretrained FastText Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74471a22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force reinstall compatible versions\n",
        "!pip install numpy==1.24.3 --force-reinstall\n",
        "!pip install gensim --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3be1be3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load FastText Burmese .vec file (ensure it's already uploaded or on your drive)\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/MyanmarNER/cc.my.300.vec', binary=False)\n",
        "# https://fasttext.cc/docs/en/crawl-vectors.html choose Burmese text .vec file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3fb18d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def build_vocab(dataset):\n",
        "    word_set = set()\n",
        "    for sentence in dataset.sentences:\n",
        "        for word in sentence:\n",
        "            word_set.add(word)\n",
        "    return word_set\n",
        "\n",
        "# Create vocab from dataset (not DataLoader!)\n",
        "vocab = build_vocab(train_data)\n",
        "\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "embedding_dim = 300\n",
        "embedding_matrix = []\n",
        "\n",
        "# Initialize PAD and UNK\n",
        "embedding_matrix.append(np.zeros(embedding_dim))  # <PAD>\n",
        "embedding_matrix.append(np.random.uniform(-0.25, 0.25, embedding_dim))  # <UNK>\n",
        "\n",
        "for word in vocab:\n",
        "    word2idx[word] = len(word2idx)\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix.append(fasttext_model[word])\n",
        "    else:\n",
        "        embedding_matrix.append(np.random.uniform(-0.25, 0.25, embedding_dim))\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15dd7706",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = CustomDataset(\"/content/drive/MyDrive/MyanmarNER/train_v5.conll\", word2idx, tag2idx)\n",
        "val_data = CustomDataset(\"/content/drive/MyDrive/MyanmarNER/val_v5.conll\", word2idx, tag2idx)\n",
        "test_data = CustomDataset(\"/content/drive/MyDrive/MyanmarNER/test_v5.conll\", word2idx, tag2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f7ee13",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NERModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, tagset_size):\n",
        "        super(NERModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            torch.FloatTensor(embedding_matrix), freeze=False\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=embedding_matrix.shape[1],\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=1,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, tagset_size)  # because it's bidirectional\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embeds = self.embedding(input_ids)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8a9396",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NERModel(embedding_matrix=embedding_matrix, hidden_dim=128, tagset_size=len(tag2idx))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
